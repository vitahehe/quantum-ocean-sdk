{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackhhl.toy.simple_generator as toy\n",
    "import trackhhl.event_model.q_event_model as emb\n",
    "from dwave.samplers import SimulatedAnnealingSampler\n",
    "import dimod\n",
    "from scipy.sparse import lil_matrix, csc_matrix, block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hamiltonian_optimized(event, params):\n",
    "    lambda_val = params.get('lambda')\n",
    "    alpha = params.get('alpha')\n",
    "    beta = params.get('beta')\n",
    "\n",
    "    modules = sorted(event.modules, key=lambda module: module.z)\n",
    "\n",
    "    \n",
    "    segments = [\n",
    "        em.segment(from_hit, to_hit)\n",
    "        for idx in range(len(modules) - 1)\n",
    "        for from_hit, to_hit in itertools.product(modules[idx].hits, modules[idx + 1].hits)\n",
    "    ]\n",
    "\n",
    "    N = len(segments)  \n",
    "\n",
    "    #initialize sparse block matrices for effviciency\n",
    "    A_ang_blocks = []\n",
    "    A_bif_blocks = []\n",
    "    A_inh_blocks = []\n",
    "    b = np.zeros(N)\n",
    "\n",
    "    #total Hamiltonian into smaller blocks->> better for memory\n",
    "    block_size = 500  \n",
    "    num_blocks = (N + block_size - 1) // block_size  \n",
    "\n",
    "    for block_idx in range(num_blocks):\n",
    "        start_idx = block_idx * block_size\n",
    "        end_idx = min(start_idx + block_size, N)\n",
    "\n",
    "        #lil_matrix for each block\n",
    "        A_ang_block = lil_matrix((end_idx - start_idx, end_idx - start_idx), dtype=np.float32)\n",
    "        A_bif_block = lil_matrix((end_idx - start_idx, end_idx - start_idx), dtype=np.float32)\n",
    "        A_inh_block = lil_matrix((end_idx - start_idx, end_idx - start_idx), dtype=np.float32)\n",
    "\n",
    "        #filling of papricas\n",
    "        for i in range(start_idx, end_idx):\n",
    "            seg_i = segments[i]\n",
    "            vect_i = seg_i.to_vect()\n",
    "            norm_i = np.linalg.norm(vect_i)\n",
    "\n",
    "            for j in range(i + 1, end_idx):  #\n",
    "                seg_j = segments[j]\n",
    "                vect_j = seg_j.to_vect()\n",
    "                norm_j = np.linalg.norm(vect_j)\n",
    "\n",
    "                cosine = np.dot(vect_i, vect_j) / (norm_i * norm_j)\n",
    "                if np.abs(cosine - 1) < 1e-9:\n",
    "                    A_ang_block[i - start_idx, j - start_idx] = 1\n",
    "                    A_ang_block[j - start_idx, i - start_idx] = 1  # Symmetry with positive sign\n",
    "\n",
    "                if seg_i.from_hit == seg_j.from_hit and seg_i.to_hit != seg_j.to_hit:\n",
    "                    A_bif_block[i - start_idx, j - start_idx] = -alpha\n",
    "                    A_bif_block[j - start_idx, i - start_idx] = -alpha  # Symmetry with negative sign\n",
    "\n",
    "                if seg_i.from_hit != seg_j.from_hit and seg_i.to_hit == seg_j.to_hit:\n",
    "                    A_bif_block[i - start_idx, j - start_idx] = -alpha\n",
    "                    A_bif_block[j - start_idx, i - start_idx] = -alpha  # Symmetry with negative sign\n",
    "\n",
    "                s_ab = int(seg_i.from_hit.module_id == 1 and seg_j.to_hit.module_id == 1)\n",
    "                if s_ab > 0:\n",
    "                    A_inh_block[i - start_idx, j - start_idx] = beta * s_ab * s_ab\n",
    "                    A_inh_block[j - start_idx, i - start_idx] = beta * s_ab * s_ab  # Symmetry with positive sign\n",
    "\n",
    "        A_ang_blocks.append(A_ang_block)\n",
    "        A_bif_blocks.append(A_bif_block)\n",
    "        A_inh_blocks.append(A_inh_block)\n",
    "\n",
    "    # combine withblock diagonal\n",
    "    A_ang = block_diag(A_ang_blocks, format='csc')\n",
    "    A_bif = block_diag(A_bif_blocks, format='csc')\n",
    "    A_inh = block_diag(A_inh_blocks, format='csc')\n",
    "\n",
    "    A = -1 * (A_ang + A_bif + A_inh)\n",
    "\n",
    "    return A, b, segments\n",
    "def generate_hamiltonian(event, params):\n",
    "    lambda_val = params.get('lambda')\n",
    "    alpha = params.get('alpha')\n",
    "    beta = params.get('beta')\n",
    "\n",
    "    modules = copy.deepcopy(event.modules)\n",
    "    modules.sort(key=lambda a: a.z)\n",
    "\n",
    "    segments = [em.segment(from_hit, to_hit) for idx in range(len(modules) - 1) for from_hit, to_hit in itertools.product(modules[idx].hits, modules[idx + 1].hits)]\n",
    "    N = len(segments)\n",
    "    A = np.zeros((N, N))\n",
    "    A_ang = np.zeros((N, N))\n",
    "    A_bif = np.zeros((N, N))\n",
    "    \n",
    "    b = np.zeros(N)\n",
    "\n",
    "    s_ab = np.zeros((N, N))\n",
    "    for i, seg_i in enumerate(segments):\n",
    "        for j, seg_j in enumerate(segments):\n",
    "            s_ab[i, j] = int(seg_i.from_hit.module_id == 1 and seg_j.to_hit.module_id == 1)\n",
    "    A_inh = np.zeros((N, N))\n",
    "\n",
    "    for i, seg_i in enumerate(segments):\n",
    "        for j, seg_j in enumerate(segments):\n",
    "            if i != j:\n",
    "                vect_i = seg_i.to_vect()\n",
    "                vect_j = seg_j.to_vect()\n",
    "                cosine = np.dot(vect_i, vect_j) / (np.linalg.norm(vect_i) * np.linalg.norm(vect_j))\n",
    "\n",
    "                eps = 1e-9\n",
    "\n",
    "                if np.abs(cosine - 1) < eps:\n",
    "                    A_ang[i, j] = 1\n",
    "\n",
    "                if (seg_i.from_hit == seg_j.from_hit) and (seg_i.to_hit != seg_j.to_hit):\n",
    "                    A_bif[i, j] = -alpha\n",
    "\n",
    "                if (seg_i.from_hit != seg_j.from_hit) and (seg_i.to_hit == seg_j.to_hit):\n",
    "                    A_bif[i, j] = -alpha\n",
    "\n",
    "                A_inh[i, j] = s_ab[i, j] * s_ab[j, i] * beta\n",
    "\n",
    "    # Compute the final expression\n",
    "    A = -1 * (A_ang + A_bif + A_inh)\n",
    "\n",
    "    components = {'A_ang': -A_ang, 'A_bif': -A_bif, 'A_inh': -A_inh}\n",
    "\n",
    "    return A, b, components, segments\n",
    "\n",
    "params = {\n",
    "    'alpha': 1.0,\n",
    "    'beta': 1.0,\n",
    "    'lambda': 100.0,} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Measure memory usage with tracemalloc\n",
    "def measure_memory(func, *args):\n",
    "    tracemalloc.start()\n",
    "    func(*args)\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    return peak\n",
    "\n",
    "# Measure time usage\n",
    "def measure_time(func, *args):\n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Measure CPU-based energy consumption (approximation using CPU times)\n",
    "def measure_energy(process):\n",
    "    cpu_times = process.cpu_times()\n",
    "    # Approximate energy usage by CPU time (user + system)\n",
    "    return (cpu_times.user + cpu_times.system) * 10  # 10 Joules per second of CPU time (approx)\n",
    "\n",
    "# Performance test for both optimized and non-optimized functions\n",
    "def performance_test(input_size):\n",
    "    process = psutil.Process()\n",
    "\n",
    "    # Optimized function performance\n",
    "    memory_opt = measure_memory(generate_hamiltonian_optimized, input_size)\n",
    "    time_opt = measure_time(generate_hamiltonian_optimized, input_size)\n",
    "    energy_opt = measure_energy(process)\n",
    "\n",
    "    # Non-Optimized function performance\n",
    "    memory_non_opt = measure_memory(generate_hamiltonian, input_size)\n",
    "    time_non_opt = measure_time(generate_hamiltonian, input_size)\n",
    "    energy_non_opt = measure_energy(process)\n",
    "\n",
    "    return (memory_opt, time_opt, energy_opt, memory_non_opt, time_non_opt, energy_non_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing size: 100x100\n",
      "Testing size: 1000x1000\n",
      "Testing size: 5000x5000\n",
      "Testing size: 10000x10000\n",
      "Testing size: 20000x20000\n",
      "MemoryError for size 20000\n",
      "Testing size: 50000x50000\n",
      "MemoryError for size 50000\n",
      "Testing size: 100000x100000\n",
      "MemoryError for size 100000\n",
      "Testing size: 160000x160000\n",
      "MemoryError for size 160000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import lil_matrix, block_diag\n",
    "import tracemalloc\n",
    "\n",
    "def generate_hamiltonian(N):\n",
    "    A = np.zeros((N, N))\n",
    "    A_ang = np.zeros((N, N))\n",
    "    A_bif = np.zeros((N, N))\n",
    "    b = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                # Simulate operatios for ang and biff term\n",
    "                A_ang[i, j] = 1 if np.random.rand() > 0.5 else 0\n",
    "                A_bif[i, j] = -1 if np.random.rand() > 0.5 else 0\n",
    "\n",
    "    A = -1 * (A_ang + A_bif)\n",
    "\n",
    "    return A, b\n",
    "\n",
    "def generate_hamiltonian_optimized(N):\n",
    "    block_size = 500\n",
    "    num_blocks = (N + block_size - 1) // block_size\n",
    "\n",
    "    A_ang_blocks = []\n",
    "    A_bif_blocks = []\n",
    "    b = np.zeros(N)\n",
    "\n",
    "    for block_idx in range(num_blocks):\n",
    "        start_idx = block_idx * block_size\n",
    "        end_idx = min(start_idx + block_size, N)\n",
    "\n",
    "        A_ang_block = lil_matrix((end_idx - start_idx, end_idx - start_idx), dtype=np.float32)\n",
    "        A_bif_block = lil_matrix((end_idx - start_idx, end_idx - start_idx), dtype=np.float32)\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            for j in range(i + 1, end_idx):\n",
    "                A_ang_block[i - start_idx, j - start_idx] = 1 if np.random.rand() > 0.5 else 0\n",
    "                A_bif_block[i - start_idx, j - start_idx] = -1 if np.random.rand() > 0.5 else 0\n",
    "\n",
    "        A_ang_blocks.append(A_ang_block)\n",
    "        A_bif_blocks.append(A_bif_block)\n",
    "\n",
    "    A_ang = block_diag(A_ang_blocks, format='csc')\n",
    "    A_bif = block_diag(A_bif_blocks, format='csc')\n",
    "\n",
    "    A = -1 * (A_ang + A_bif)\n",
    "\n",
    "    return A, b\n",
    "\n",
    "#helper function to measure execution time and memory \n",
    "def measure_performance(func, N):\n",
    "    try:\n",
    "        tracemalloc.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        snapshot1 = tracemalloc.take_snapshot()\n",
    "        func(N)\n",
    "\n",
    "    \n",
    "        snapshot2 = tracemalloc.take_snapshot()\n",
    "        end_time = time.time()\n",
    "\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        stats = snapshot2.compare_to(snapshot1, 'lineno')\n",
    "        total_memory = sum([stat.size_diff for stat in stats]) / (1024 ** 2)  # Convert to MB\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        return time_taken, total_memory\n",
    "\n",
    "    except MemoryError:\n",
    "        print(f\"MemoryError for size {N}\")\n",
    "        return None, None\n",
    "input_sizes = [100, 1000, 5000, 10000, 20000, 50000, 100000, 160000, 200000]  # Adjust or add more sizes as needed\n",
    "times_non_opt = []\n",
    "times_opt = []\n",
    "mem_non_opt = []\n",
    "mem_opt = []\n",
    "\n",
    "for size in input_sizes:\n",
    "    print(f\"Testing size: {size}x{size}\")\n",
    "    \n",
    "    time_non_opt, mem_non_opt_used = measure_performance(generate_hamiltonian, size)\n",
    "    times_non_opt.append(time_non_opt)\n",
    "    mem_non_opt.append(mem_non_opt_used)\n",
    "\n",
    "    time_opt, mem_opt_used = measure_performance(generate_hamiltonian_optimized, size)\n",
    "    times_opt.append(time_opt)\n",
    "    mem_opt.append(mem_opt_used)\n",
    "\n",
    "times_non_opt = [t if t is not None else float('nan') for t in times_non_opt]\n",
    "times_opt = [t if t is not None else float('nan') for t in times_opt]\n",
    "mem_non_opt = [m if m is not None else float('nan') for m in mem_non_opt]\n",
    "mem_opt = [m if m is not None else float('nan') for m in mem_opt]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(input_sizes, times_non_opt, label='Non-Optimized', marker='o')\n",
    "plt.plot(input_sizes, times_opt, label='Optimized', marker='o')\n",
    "plt.xlabel('Matrix Size (N x N)')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Execution Time vs Matrix Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(input_sizes, mem_non_opt, label='Non-Optimized', marker='o')\n",
    "plt.plot(input_sizes, mem_opt, label='Optimized', marker='o')\n",
    "plt.xlabel('Matrix Size (N x N)')\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "plt.title('Memory Usage vs Matrix Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Run the performance comparison\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m compare_performance()\n",
      "Cell \u001b[1;32mIn[4], line 71\u001b[0m, in \u001b[0;36mcompare_performance\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m tracemalloc\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     70\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 71\u001b[0m qubosolver_non_optimized(A, b)\n\u001b[0;32m     72\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     73\u001b[0m current, peak \u001b[38;5;241m=\u001b[39m tracemalloc\u001b[38;5;241m.\u001b[39mget_traced_memory()\n",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36mqubosolver_non_optimized\u001b[1;34m(A, b)\u001b[0m\n\u001b[0;32m      9\u001b[0m matrix_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(A\u001b[38;5;241m.\u001b[39mtoarray()) \n\u001b[0;32m     11\u001b[0m bqm \u001b[38;5;241m=\u001b[39m dimod\u001b[38;5;241m.\u001b[39mBinaryQuadraticModel(b, matrix_A, \u001b[38;5;241m0.0\u001b[39m, dimod\u001b[38;5;241m.\u001b[39mBINARY)\n\u001b[1;32m---> 12\u001b[0m q, off \u001b[38;5;241m=\u001b[39m bqm\u001b[38;5;241m.\u001b[39mto_qubo()\n\u001b[0;32m     14\u001b[0m sampler \u001b[38;5;241m=\u001b[39m SimulatedAnnealingSampler()\n\u001b[0;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39msample_qubo(q, num_reads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vita\\anaconda3\\Lib\\site-packages\\dimod\\binary\\binary_quadratic_model.py:2472\u001b[0m, in \u001b[0;36mBinaryQuadraticModel.to_qubo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_qubo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Mapping[Tuple[Variable, Variable], Bias], Bias]:\n\u001b[0;32m   2461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a binary quadratic model to QUBO format.\u001b[39;00m\n\u001b[0;32m   2462\u001b[0m \n\u001b[0;32m   2463\u001b[0m \u001b[38;5;124;03m    If the binary quadratic model's vartype is not :class:`.Vartype.BINARY`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[38;5;124;03m        constant offset of the binary quadratic model.\u001b[39;00m\n\u001b[0;32m   2471\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2472\u001b[0m     qubo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary\u001b[38;5;241m.\u001b[39mquadratic)\n\u001b[0;32m   2473\u001b[0m     qubo\u001b[38;5;241m.\u001b[39mupdate(((v, v), bias) \u001b[38;5;28;01mfor\u001b[39;00m v, bias \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary\u001b[38;5;241m.\u001b[39mlinear\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   2474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qubo, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary\u001b[38;5;241m.\u001b[39moffset\n",
      "File \u001b[1;32mc:\\Users\\Vita\\anaconda3\\Lib\\site-packages\\dimod\\views\\quadratic.py:204\u001b[0m, in \u001b[0;36mQuadratic.__getitem__\u001b[1;34m(self, uv)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, uv: Tuple[Variable, Variable]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Bias:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mget_quadratic(\u001b[38;5;241m*\u001b[39muv)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import tracemalloc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def qubosolver_non_optimized(A, b):\n",
    "\n",
    "    matrix_A = np.array(A.toarray()) \n",
    "    \n",
    "    bqm = dimod.BinaryQuadraticModel(b, matrix_A, 0.0, dimod.BINARY)\n",
    "    q, off = bqm.to_qubo()\n",
    "\n",
    "    sampler = SimulatedAnnealingSampler()\n",
    "    response = sampler.sample_qubo(q, num_reads=100)\n",
    "    best_sample = response.first.sample\n",
    "    sol_sample = np.array(list(best_sample.values()))\n",
    "\n",
    "    return sol_sample\n",
    "\n",
    "def qubosolver_optimized(A, b):\n",
    "    # Core computation\n",
    "    A = csc_matrix(A)\n",
    "    bqm = dimod.BinaryQuadraticModel.empty(dimod.BINARY)\n",
    "\n",
    "    bqm.add_variables_from({i: b[i] for i in range(len(b))})\n",
    "\n",
    "    row, col = A.nonzero()  \n",
    "    for i, j in zip(row, col):\n",
    "        if i != j:  \n",
    "            bqm.add_interaction(i, j, A[i, j])\n",
    "\n",
    "    sampler = SimulatedAnnealingSampler()\n",
    "    response = sampler.sample(bqm, num_reads=100)\n",
    "\n",
    "    best_sample = response.first.sample\n",
    "    sol_sample = np.fromiter(best_sample.values(), dtype=int)  \n",
    "\n",
    "\n",
    "    return sol_sample\n",
    "\n",
    "def generate_sparse_matrix(n, density=0.01):\n",
    "    return sp.random(n, n, density=density, data_rvs=lambda x: np.ones(x)).astype(int)\n",
    "\n",
    "def compare_performance():\n",
    "    sizes = [100, 500, 1000, 5000, 10000, 20000, 50000, 100000, 160000 ]  # You can increase the size range\n",
    "    time_optimized = []\n",
    "    time_non_optimized = []\n",
    "    memory_optimized = []\n",
    "    memory_non_optimized = []\n",
    "    \n",
    "    for n in sizes:\n",
    "        try:\n",
    "            # Generate test data\n",
    "            A = generate_sparse_matrix(n)\n",
    "            b = np.random.randint(2, size=n)\n",
    "\n",
    "            # Measure performance for qubosolver_optimized\n",
    "            tracemalloc.start()\n",
    "            start_time = time.time()\n",
    "            qubosolver_optimized(A, b)\n",
    "            end_time = time.time()\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            time_optimized.append(end_time - start_time)\n",
    "            memory_optimized.append(peak)\n",
    "            tracemalloc.stop()\n",
    "\n",
    "            # Measure performance for qubosolver_non_optimized\n",
    "            tracemalloc.start()\n",
    "            start_time = time.time()\n",
    "            qubosolver_non_optimized(A, b)\n",
    "            end_time = time.time()\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            time_non_optimized.append(end_time - start_time)\n",
    "            memory_non_optimized.append(peak)\n",
    "            tracemalloc.stop()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for matrix size {n}: {e}\")\n",
    "            # Append None or last known value to avoid breaking the plot\n",
    "            if time_optimized:\n",
    "                time_optimized.append(time_optimized[-1])\n",
    "                memory_optimized.append(memory_optimized[-1])\n",
    "            else:\n",
    "                time_optimized.append(None)\n",
    "                memory_optimized.append(None)\n",
    "\n",
    "            if time_non_optimized:\n",
    "                time_non_optimized.append(time_non_optimized[-1])\n",
    "                memory_non_optimized.append(memory_non_optimized[-1])\n",
    "            else:\n",
    "                time_non_optimized.append(None)\n",
    "                memory_non_optimized.append(None)\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Time comparison\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(sizes, time_optimized, label='Optimized Time', marker='o')\n",
    "    plt.plot(sizes, time_non_optimized, label='Non-Optimized Time', marker='x')\n",
    "    plt.xlabel('Matrix Size (n x n)')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('Time Performance Comparison')\n",
    "    plt.legend()\n",
    "\n",
    "    # Memory comparison\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(sizes, memory_optimized, label='Optimized Memory', marker='o')\n",
    "    plt.plot(sizes, memory_non_optimized, label='Non-Optimized Memory', marker='x')\n",
    "    plt.xlabel('Matrix Size (n x n)')\n",
    "    plt.ylabel('Memory Usage (bytes)')\n",
    "    plt.title('Memory Performance Comparison')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the performance comparison\n",
    "compare_performance()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
